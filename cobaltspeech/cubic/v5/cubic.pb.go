// Copyright (2022--present) Cobalt Speech and Language Inc.

// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//*
//Cobalt ASR is a state-of-the-art speech recognition system, which uses deep-learning models for fast, accurate speech recognition.

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        (unknown)
// source: cobaltspeech/cubic/v5/cubic.proto

package cubicv5

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// Byte order of multi-byte data
type ByteOrder int32

const (
	// BYTE_ORDER_UNSPECIFIED is the default value of this type.
	ByteOrder_BYTE_ORDER_UNSPECIFIED ByteOrder = 0
	// Little Endian byte order
	ByteOrder_BYTE_ORDER_LITTLE_ENDIAN ByteOrder = 1
	// Big Endian byte order
	ByteOrder_BYTE_ORDER_BIG_ENDIAN ByteOrder = 2
)

// Enum value maps for ByteOrder.
var (
	ByteOrder_name = map[int32]string{
		0: "BYTE_ORDER_UNSPECIFIED",
		1: "BYTE_ORDER_LITTLE_ENDIAN",
		2: "BYTE_ORDER_BIG_ENDIAN",
	}
	ByteOrder_value = map[string]int32{
		"BYTE_ORDER_UNSPECIFIED":   0,
		"BYTE_ORDER_LITTLE_ENDIAN": 1,
		"BYTE_ORDER_BIG_ENDIAN":    2,
	}
)

func (x ByteOrder) Enum() *ByteOrder {
	p := new(ByteOrder)
	*p = x
	return p
}

func (x ByteOrder) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ByteOrder) Descriptor() protoreflect.EnumDescriptor {
	return file_cobaltspeech_cubic_v5_cubic_proto_enumTypes[0].Descriptor()
}

func (ByteOrder) Type() protoreflect.EnumType {
	return &file_cobaltspeech_cubic_v5_cubic_proto_enumTypes[0]
}

func (x ByteOrder) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ByteOrder.Descriptor instead.
func (ByteOrder) EnumDescriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{0}
}

// The encoding of the audio data to be sent for recognition.
type AudioEncoding int32

const (
	// AUDIO_ENCODING_UNSPECIFIED is the default value of this type and will
	// result in an error.
	AudioEncoding_AUDIO_ENCODING_UNSPECIFIED AudioEncoding = 0
	// PCM signed-integer
	AudioEncoding_AUDIO_ENCODING_SIGNED AudioEncoding = 1
	// PCM unsigned-integer
	AudioEncoding_AUDIO_ENCODING_UNSIGNED AudioEncoding = 2
	// PCM IEEE-Float
	AudioEncoding_AUDIO_ENCODING_IEEE_FLOAT AudioEncoding = 3
	// G.711 mu-law
	AudioEncoding_AUDIO_ENCODING_ULAW AudioEncoding = 4
	// G.711 a-law
	AudioEncoding_AUDIO_ENCODING_ALAW AudioEncoding = 5
)

// Enum value maps for AudioEncoding.
var (
	AudioEncoding_name = map[int32]string{
		0: "AUDIO_ENCODING_UNSPECIFIED",
		1: "AUDIO_ENCODING_SIGNED",
		2: "AUDIO_ENCODING_UNSIGNED",
		3: "AUDIO_ENCODING_IEEE_FLOAT",
		4: "AUDIO_ENCODING_ULAW",
		5: "AUDIO_ENCODING_ALAW",
	}
	AudioEncoding_value = map[string]int32{
		"AUDIO_ENCODING_UNSPECIFIED": 0,
		"AUDIO_ENCODING_SIGNED":      1,
		"AUDIO_ENCODING_UNSIGNED":    2,
		"AUDIO_ENCODING_IEEE_FLOAT":  3,
		"AUDIO_ENCODING_ULAW":        4,
		"AUDIO_ENCODING_ALAW":        5,
	}
)

func (x AudioEncoding) Enum() *AudioEncoding {
	p := new(AudioEncoding)
	*p = x
	return p
}

func (x AudioEncoding) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (AudioEncoding) Descriptor() protoreflect.EnumDescriptor {
	return file_cobaltspeech_cubic_v5_cubic_proto_enumTypes[1].Descriptor()
}

func (AudioEncoding) Type() protoreflect.EnumType {
	return &file_cobaltspeech_cubic_v5_cubic_proto_enumTypes[1]
}

func (x AudioEncoding) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use AudioEncoding.Descriptor instead.
func (AudioEncoding) EnumDescriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{1}
}

type AudioFormatHeadered int32

const (
	// AUDIO_FORMAT_HEADERED_UNSPECIFIED is the default value of this type.
	AudioFormatHeadered_AUDIO_FORMAT_HEADERED_UNSPECIFIED AudioFormatHeadered = 0
	// WAV with RIFF headers
	AudioFormatHeadered_AUDIO_FORMAT_HEADERED_WAV AudioFormatHeadered = 1
	// MP3 format with a valid frame header at the beginning of data
	AudioFormatHeadered_AUDIO_FORMAT_HEADERED_MP3 AudioFormatHeadered = 2
	// FLAC format
	AudioFormatHeadered_AUDIO_FORMAT_HEADERED_FLAC AudioFormatHeadered = 3
	// Opus format with OGG header
	AudioFormatHeadered_AUDIO_FORMAT_HEADERED_OGG_OPUS AudioFormatHeadered = 4
)

// Enum value maps for AudioFormatHeadered.
var (
	AudioFormatHeadered_name = map[int32]string{
		0: "AUDIO_FORMAT_HEADERED_UNSPECIFIED",
		1: "AUDIO_FORMAT_HEADERED_WAV",
		2: "AUDIO_FORMAT_HEADERED_MP3",
		3: "AUDIO_FORMAT_HEADERED_FLAC",
		4: "AUDIO_FORMAT_HEADERED_OGG_OPUS",
	}
	AudioFormatHeadered_value = map[string]int32{
		"AUDIO_FORMAT_HEADERED_UNSPECIFIED": 0,
		"AUDIO_FORMAT_HEADERED_WAV":         1,
		"AUDIO_FORMAT_HEADERED_MP3":         2,
		"AUDIO_FORMAT_HEADERED_FLAC":        3,
		"AUDIO_FORMAT_HEADERED_OGG_OPUS":    4,
	}
)

func (x AudioFormatHeadered) Enum() *AudioFormatHeadered {
	p := new(AudioFormatHeadered)
	*p = x
	return p
}

func (x AudioFormatHeadered) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (AudioFormatHeadered) Descriptor() protoreflect.EnumDescriptor {
	return file_cobaltspeech_cubic_v5_cubic_proto_enumTypes[2].Descriptor()
}

func (AudioFormatHeadered) Type() protoreflect.EnumType {
	return &file_cobaltspeech_cubic_v5_cubic_proto_enumTypes[2]
}

func (x AudioFormatHeadered) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use AudioFormatHeadered.Descriptor instead.
func (AudioFormatHeadered) EnumDescriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{2}
}

// The top-level message sent by the client for the `Version` method.
type VersionRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *VersionRequest) Reset() {
	*x = VersionRequest{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *VersionRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*VersionRequest) ProtoMessage() {}

func (x *VersionRequest) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use VersionRequest.ProtoReflect.Descriptor instead.
func (*VersionRequest) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{0}
}

// The message sent by the server for the `Version` method.
type VersionResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Version of the server handling these requests.
	Version       string `protobuf:"bytes,1,opt,name=version,proto3" json:"version,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *VersionResponse) Reset() {
	*x = VersionResponse{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *VersionResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*VersionResponse) ProtoMessage() {}

func (x *VersionResponse) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use VersionResponse.ProtoReflect.Descriptor instead.
func (*VersionResponse) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{1}
}

func (x *VersionResponse) GetVersion() string {
	if x != nil {
		return x.Version
	}
	return ""
}

// The top-level message sent by the client for the `ListModels` method.
type ListModelsRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListModelsRequest) Reset() {
	*x = ListModelsRequest{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListModelsRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListModelsRequest) ProtoMessage() {}

func (x *ListModelsRequest) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListModelsRequest.ProtoReflect.Descriptor instead.
func (*ListModelsRequest) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{2}
}

// The message returned to the client by the `ListModels` method.
type ListModelsResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// List of models available for use that match the request.
	Models        []*Model `protobuf:"bytes,1,rep,name=models,proto3" json:"models,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ListModelsResponse) Reset() {
	*x = ListModelsResponse{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ListModelsResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ListModelsResponse) ProtoMessage() {}

func (x *ListModelsResponse) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ListModelsResponse.ProtoReflect.Descriptor instead.
func (*ListModelsResponse) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{3}
}

func (x *ListModelsResponse) GetModels() []*Model {
	if x != nil {
		return x.Models
	}
	return nil
}

// The top-level messages sent by the client for the `StreamingRecognize`
// method. In this streaming call, multiple `StreamingRecognizeRequest` messages
// should be sent. The first message must contain a `RecognitionConfig` message
// only, and all subsequent messages must contain `RecognitionAudio` only. All
// `RecognitionAudio` messages must contain non-empty audio. If audio content is
// empty, the server may choose to interpret it as end of stream and stop
// accepting any further messages.
type StreamingRecognizeRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Request:
	//
	//	*StreamingRecognizeRequest_Config
	//	*StreamingRecognizeRequest_Audio
	Request       isStreamingRecognizeRequest_Request `protobuf_oneof:"request"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StreamingRecognizeRequest) Reset() {
	*x = StreamingRecognizeRequest{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StreamingRecognizeRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamingRecognizeRequest) ProtoMessage() {}

func (x *StreamingRecognizeRequest) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamingRecognizeRequest.ProtoReflect.Descriptor instead.
func (*StreamingRecognizeRequest) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{4}
}

func (x *StreamingRecognizeRequest) GetRequest() isStreamingRecognizeRequest_Request {
	if x != nil {
		return x.Request
	}
	return nil
}

func (x *StreamingRecognizeRequest) GetConfig() *RecognitionConfig {
	if x != nil {
		if x, ok := x.Request.(*StreamingRecognizeRequest_Config); ok {
			return x.Config
		}
	}
	return nil
}

func (x *StreamingRecognizeRequest) GetAudio() *RecognitionAudio {
	if x != nil {
		if x, ok := x.Request.(*StreamingRecognizeRequest_Audio); ok {
			return x.Audio
		}
	}
	return nil
}

type isStreamingRecognizeRequest_Request interface {
	isStreamingRecognizeRequest_Request()
}

type StreamingRecognizeRequest_Config struct {
	Config *RecognitionConfig `protobuf:"bytes,1,opt,name=config,proto3,oneof"`
}

type StreamingRecognizeRequest_Audio struct {
	Audio *RecognitionAudio `protobuf:"bytes,2,opt,name=audio,proto3,oneof"`
}

func (*StreamingRecognizeRequest_Config) isStreamingRecognizeRequest_Request() {}

func (*StreamingRecognizeRequest_Audio) isStreamingRecognizeRequest_Request() {}

// The messages returned by the server for the `StreamingRecognize` request.
// Multiple messages of this type will be delivered on the stream, for multiple
// results, as soon as results are available from the audio submitted so far. If
// the audio has multiple channels, the results of all channels will be
// interleaved. Results of each individual channel will be chronological.
// However, there is no guarantee of the order of results across channels.
//
// Clients should process both the `result` and `error` fields in each message.
// At least one of these fields will be present in the message. If both `result`
// and `error` are present, the result is still valid.
type StreamingRecognizeResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A new recognition result. This field will be unset if a new result is not
	// yet available.
	Result *RecognitionResult `protobuf:"bytes,1,opt,name=result,proto3" json:"result,omitempty"`
	// A non-fatal error message. If a server encountered a non-fatal error when
	// processing the recognition request, it will be returned in this message.
	// The server will continue to process audio and produce further results.
	// Clients can continue streaming audio even after receiving these messages.
	// This error message is meant to be informational.
	//
	// An example of when these errors maybe produced: audio is sampled at a lower
	// rate than expected by model, producing possibly less accurate results.
	//
	// This field will be unset if there is no error to report.
	Error         *RecognitionError `protobuf:"bytes,2,opt,name=error,proto3" json:"error,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StreamingRecognizeResponse) Reset() {
	*x = StreamingRecognizeResponse{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StreamingRecognizeResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StreamingRecognizeResponse) ProtoMessage() {}

func (x *StreamingRecognizeResponse) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StreamingRecognizeResponse.ProtoReflect.Descriptor instead.
func (*StreamingRecognizeResponse) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{5}
}

func (x *StreamingRecognizeResponse) GetResult() *RecognitionResult {
	if x != nil {
		return x.Result
	}
	return nil
}

func (x *StreamingRecognizeResponse) GetError() *RecognitionError {
	if x != nil {
		return x.Error
	}
	return nil
}

// The top-level message sent by the client for the `CompileContext` request. It
// contains a list of phrases or words, paired with a context token included in
// the model being used. The token specifies a category such as "menu_item",
// "airport", "contact", "product_name" etc. The context token is used to
// determine the places in the recognition output where the provided list of
// phrases or words may appear. The allowed context tokens for a given model can
// be found in its `ModelAttributes.ContextInfo` obtained via the `ListModels`
// method.
type CompileContextRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Unique identifier of the model to compile the context information for. The
	// model chosen needs to support context which can be verified by checking its
	// `ModelAttributes.ContextInfo` obtained via `ListModels`.
	ModelId string `protobuf:"bytes,1,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`
	// The token that is associated with the provided list of phrases or words
	// (e.g "menu_item", "airport" etc.). Must be one of the tokens included in
	// the model being used, which can be retrieved by calling the `ListModels`
	// method.
	Token string `protobuf:"bytes,2,opt,name=token,proto3" json:"token,omitempty"`
	// List of phrases and/or words to be compiled.
	Phrases       []*ContextPhrase `protobuf:"bytes,3,rep,name=phrases,proto3" json:"phrases,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CompileContextRequest) Reset() {
	*x = CompileContextRequest{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CompileContextRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CompileContextRequest) ProtoMessage() {}

func (x *CompileContextRequest) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CompileContextRequest.ProtoReflect.Descriptor instead.
func (*CompileContextRequest) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{6}
}

func (x *CompileContextRequest) GetModelId() string {
	if x != nil {
		return x.ModelId
	}
	return ""
}

func (x *CompileContextRequest) GetToken() string {
	if x != nil {
		return x.Token
	}
	return ""
}

func (x *CompileContextRequest) GetPhrases() []*ContextPhrase {
	if x != nil {
		return x.Phrases
	}
	return nil
}

// The message returned to the client by the `CompileContext` method.
type CompileContextResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Context information in a compact form that is efficient for use in
	// subsequent recognition requests. The size of the compiled form will depend
	// on the amount of text that was sent for compilation. For 1000 words it's
	// generally less than 100 kilobytes.
	Context       *CompiledContext `protobuf:"bytes,1,opt,name=context,proto3" json:"context,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CompileContextResponse) Reset() {
	*x = CompileContextResponse{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CompileContextResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CompileContextResponse) ProtoMessage() {}

func (x *CompileContextResponse) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CompileContextResponse.ProtoReflect.Descriptor instead.
func (*CompileContextResponse) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{7}
}

func (x *CompileContextResponse) GetContext() *CompiledContext {
	if x != nil {
		return x.Context
	}
	return nil
}

// Configuration for setting up a Recognizer
type RecognitionConfig struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Unique identifier of the model to use, as obtained from a `Model` message.
	ModelId string `protobuf:"bytes,1,opt,name=model_id,json=modelId,proto3" json:"model_id,omitempty"`
	// Format of the audio to be sent for recognition.
	//
	// Depending on how they are configured, server instances of this service may
	// not support all the formats provided in the API. One format that is
	// guaranteed to be supported is the RAW format with little-endian 16-bit
	// signed samples with the sample rate matching that of the model being
	// requested.
	//
	// Types that are valid to be assigned to AudioFormat:
	//
	//	*RecognitionConfig_AudioFormatRaw
	//	*RecognitionConfig_AudioFormatHeadered
	AudioFormat isRecognitionConfig_AudioFormat `protobuf_oneof:"audio_format"`
	// This is an optional field. If the audio has multiple channels, this field
	// can be configured with the list of channel indices that should be
	// considered for the recognition task. These channels are 0-indexed.
	//
	// Example: `[0]` for a mono file, `[0, 1]` for a stereo file.
	// Example: `[1]` to only transcribe the second channel of a stereo file.
	//
	// If this field is not set, all the channels in the audio will be processed.
	//
	// Channels that are present in the audio may be omitted, but it is an error
	// to include a channel index in this field that is not present in the audio.
	// Channels may be listed in any order but the same index may not be repeated
	// in this list.
	//
	// BAD: `[0, 2]` for a stereo file; BAD: `[0, 0]` for a mono file.
	SelectedAudioChannels []uint32 `protobuf:"varint,4,rep,packed,name=selected_audio_channels,json=selectedAudioChannels,proto3" json:"selected_audio_channels,omitempty"`
	// This is an optional field. It can be used to indicate that the audio being
	// streamed to the recognizer is offset from the original stream by the
	// provided duration in milliseconds. This offset will be added to all
	// timestamps in results returned by the recognizer.
	//
	// The default value of this field is 0ms, so the timestamps in the
	// recognition result will not be modified.
	//
	// Example use case where this field can be helpful: if a recognition session
	// was interrupted and audio needs to be sent to a new session from the point
	// where the session was previously interrupted, the offset could be set to
	// the point where the interruption had happened.
	AudioTimeOffsetMs uint64 `protobuf:"varint,5,opt,name=audio_time_offset_ms,json=audioTimeOffsetMs,proto3" json:"audio_time_offset_ms,omitempty"`
	// This is an optional field. If this is set to `true`, each result will
	// include word level details of the transcript. These details are specified
	// in the `WordDetails` message. If set to `false`, no word-level details will
	// be returned. The default is `false`.
	EnableWordDetails bool `protobuf:"varint,6,opt,name=enable_word_details,json=enableWordDetails,proto3" json:"enable_word_details,omitempty"`
	// This is an optional field. If this is set to true, each result will include
	// a confusion network. If set to `false`, no confusion network will be
	// returned. The default is `false`. If the model being used does not support
	// returning a confusion network, this field will have no effect. Tokens in
	// the confusion network always correspond to tokens in the `transcript_raw`
	// returned.
	EnableConfusionNetwork bool `protobuf:"varint,7,opt,name=enable_confusion_network,json=enableConfusionNetwork,proto3" json:"enable_confusion_network,omitempty"`
	// This is an optional field. If there is any metadata associated with the
	// audio being sent, use this field to provide it to the recognizer. The
	// server may record this metadata when processing the request. The server
	// does not use this field for any other purpose.
	Metadata *RecognitionMetadata `protobuf:"bytes,8,opt,name=metadata,proto3" json:"metadata,omitempty"`
	// This is an optional field for providing any additional context information
	// that may aid speech recognition. This can also be used to add
	// out-of-vocabulary words to the model or boost recognition of specific
	// proper names or commands. Context information must be pre-compiled via the
	// `CompileContext()` method.
	Context       *RecognitionContext `protobuf:"bytes,9,opt,name=context,proto3" json:"context,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RecognitionConfig) Reset() {
	*x = RecognitionConfig{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RecognitionConfig) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognitionConfig) ProtoMessage() {}

func (x *RecognitionConfig) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognitionConfig.ProtoReflect.Descriptor instead.
func (*RecognitionConfig) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{8}
}

func (x *RecognitionConfig) GetModelId() string {
	if x != nil {
		return x.ModelId
	}
	return ""
}

func (x *RecognitionConfig) GetAudioFormat() isRecognitionConfig_AudioFormat {
	if x != nil {
		return x.AudioFormat
	}
	return nil
}

func (x *RecognitionConfig) GetAudioFormatRaw() *AudioFormatRAW {
	if x != nil {
		if x, ok := x.AudioFormat.(*RecognitionConfig_AudioFormatRaw); ok {
			return x.AudioFormatRaw
		}
	}
	return nil
}

func (x *RecognitionConfig) GetAudioFormatHeadered() AudioFormatHeadered {
	if x != nil {
		if x, ok := x.AudioFormat.(*RecognitionConfig_AudioFormatHeadered); ok {
			return x.AudioFormatHeadered
		}
	}
	return AudioFormatHeadered_AUDIO_FORMAT_HEADERED_UNSPECIFIED
}

func (x *RecognitionConfig) GetSelectedAudioChannels() []uint32 {
	if x != nil {
		return x.SelectedAudioChannels
	}
	return nil
}

func (x *RecognitionConfig) GetAudioTimeOffsetMs() uint64 {
	if x != nil {
		return x.AudioTimeOffsetMs
	}
	return 0
}

func (x *RecognitionConfig) GetEnableWordDetails() bool {
	if x != nil {
		return x.EnableWordDetails
	}
	return false
}

func (x *RecognitionConfig) GetEnableConfusionNetwork() bool {
	if x != nil {
		return x.EnableConfusionNetwork
	}
	return false
}

func (x *RecognitionConfig) GetMetadata() *RecognitionMetadata {
	if x != nil {
		return x.Metadata
	}
	return nil
}

func (x *RecognitionConfig) GetContext() *RecognitionContext {
	if x != nil {
		return x.Context
	}
	return nil
}

type isRecognitionConfig_AudioFormat interface {
	isRecognitionConfig_AudioFormat()
}

type RecognitionConfig_AudioFormatRaw struct {
	// Audio is raw data without any headers
	AudioFormatRaw *AudioFormatRAW `protobuf:"bytes,2,opt,name=audio_format_raw,json=audioFormatRaw,proto3,oneof"`
}

type RecognitionConfig_AudioFormatHeadered struct {
	// Audio has a self-describing header. Headers are expected to be sent at
	// the beginning of the entire audio file/stream, and not in every
	// `RecognitionAudio` message.
	//
	// The default value of this type is AUDIO_FORMAT_HEADERED_UNSPECIFIED. If
	// this value is used, the server may attempt to detect the format of the
	// audio. However, it is recommended that the exact format be specified.
	AudioFormatHeadered AudioFormatHeadered `protobuf:"varint,3,opt,name=audio_format_headered,json=audioFormatHeadered,proto3,enum=cobaltspeech.cubic.v5.AudioFormatHeadered,oneof"`
}

func (*RecognitionConfig_AudioFormatRaw) isRecognitionConfig_AudioFormat() {}

func (*RecognitionConfig_AudioFormatHeadered) isRecognitionConfig_AudioFormat() {}

// Details of audio in raw format
type AudioFormatRAW struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Encoding of the samples. It must be specified explicitly and using the
	// default value of `AUDIO_ENCODING_UNSPECIFIED` will result in an error.
	Encoding AudioEncoding `protobuf:"varint,1,opt,name=encoding,proto3,enum=cobaltspeech.cubic.v5.AudioEncoding" json:"encoding,omitempty"`
	// Bit depth of each sample (e.g. 8, 16, 24, 32, etc.). This is a required
	// field.
	BitDepth uint32 `protobuf:"varint,2,opt,name=bit_depth,json=bitDepth,proto3" json:"bit_depth,omitempty"`
	// Byte order of the samples. This field must be set to a value other than
	// `BYTE_ORDER_UNSPECIFIED` when the `bit_depth` is greater than 8.
	ByteOrder ByteOrder `protobuf:"varint,3,opt,name=byte_order,json=byteOrder,proto3,enum=cobaltspeech.cubic.v5.ByteOrder" json:"byte_order,omitempty"`
	// Sampling rate in Hz. This is a required field.
	SampleRate uint32 `protobuf:"varint,4,opt,name=sample_rate,json=sampleRate,proto3" json:"sample_rate,omitempty"`
	// Number of channels present in the audio. E.g.: 1 (mono), 2 (stereo), etc.
	// This is a required field.
	Channels      uint32 `protobuf:"varint,5,opt,name=channels,proto3" json:"channels,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AudioFormatRAW) Reset() {
	*x = AudioFormatRAW{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AudioFormatRAW) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AudioFormatRAW) ProtoMessage() {}

func (x *AudioFormatRAW) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AudioFormatRAW.ProtoReflect.Descriptor instead.
func (*AudioFormatRAW) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{9}
}

func (x *AudioFormatRAW) GetEncoding() AudioEncoding {
	if x != nil {
		return x.Encoding
	}
	return AudioEncoding_AUDIO_ENCODING_UNSPECIFIED
}

func (x *AudioFormatRAW) GetBitDepth() uint32 {
	if x != nil {
		return x.BitDepth
	}
	return 0
}

func (x *AudioFormatRAW) GetByteOrder() ByteOrder {
	if x != nil {
		return x.ByteOrder
	}
	return ByteOrder_BYTE_ORDER_UNSPECIFIED
}

func (x *AudioFormatRAW) GetSampleRate() uint32 {
	if x != nil {
		return x.SampleRate
	}
	return 0
}

func (x *AudioFormatRAW) GetChannels() uint32 {
	if x != nil {
		return x.Channels
	}
	return 0
}

// Metadata associated with the audio to be recognized.
type RecognitionMetadata struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Any custom metadata that the client wants to associate with the recording.
	// This could be a simple string (e.g. a tracing ID) or structured data
	// (e.g. JSON).
	CustomMetadata string `protobuf:"bytes,1,opt,name=custom_metadata,json=customMetadata,proto3" json:"custom_metadata,omitempty"`
	// This is an optional field to specify custom ID to identify the recognition
	// session. The custom ID must be a string of upto 64 bytes, and only alphabets,
	// digits, hyphens and underscores are allowed. This ID may be recorded by the
	// server in logs or other storage, and should therefore not include any
	// sensitive information.
	CustomId      string `protobuf:"bytes,2,opt,name=custom_id,json=customId,proto3" json:"custom_id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RecognitionMetadata) Reset() {
	*x = RecognitionMetadata{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RecognitionMetadata) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognitionMetadata) ProtoMessage() {}

func (x *RecognitionMetadata) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognitionMetadata.ProtoReflect.Descriptor instead.
func (*RecognitionMetadata) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{10}
}

func (x *RecognitionMetadata) GetCustomMetadata() string {
	if x != nil {
		return x.CustomMetadata
	}
	return ""
}

func (x *RecognitionMetadata) GetCustomId() string {
	if x != nil {
		return x.CustomId
	}
	return ""
}

// A collection of additional context information that may aid speech
// recognition. This can be used to add out-of-vocabulary words to the model or
// to boost recognition of specific proper names or commands.
type RecognitionContext struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// List of compiled context information, with each entry being compiled from a
	// list of words or phrases using the `CompileContext` method.
	Compiled      []*CompiledContext `protobuf:"bytes,1,rep,name=compiled,proto3" json:"compiled,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RecognitionContext) Reset() {
	*x = RecognitionContext{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RecognitionContext) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognitionContext) ProtoMessage() {}

func (x *RecognitionContext) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognitionContext.ProtoReflect.Descriptor instead.
func (*RecognitionContext) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{11}
}

func (x *RecognitionContext) GetCompiled() []*CompiledContext {
	if x != nil {
		return x.Compiled
	}
	return nil
}

// Context information in a compact form that is efficient for use in subsequent
// recognition requests. The size of the compiled form will depend on the amount
// of text that was sent for compilation. For 1000 words it's generally less
// than 100 kilobytes.
type CompiledContext struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The context information compiled by the `CompileContext` method.
	Data          []byte `protobuf:"bytes,1,opt,name=data,proto3" json:"data,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CompiledContext) Reset() {
	*x = CompiledContext{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CompiledContext) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CompiledContext) ProtoMessage() {}

func (x *CompiledContext) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CompiledContext.ProtoReflect.Descriptor instead.
func (*CompiledContext) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{12}
}

func (x *CompiledContext) GetData() []byte {
	if x != nil {
		return x.Data
	}
	return nil
}

// A phrase or word that is to be compiled into context information that can be
// later used to improve speech recognition during a `StreamingRecognize` call.
// Along with the phrase or word itself, there is an optional boost parameter
// that can be used to boost the likelihood of the phrase or word in the
// recognition output.
type ContextPhrase struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The actual phrase or word.
	Text string `protobuf:"bytes,1,opt,name=text,proto3" json:"text,omitempty"`
	// This is an optional field. The boost factor is a positive number which is
	// used to multiply the probability of the phrase or word appearing in the
	// output. This setting can be used to differentiate between similar sounding
	// words, with the desired word given a bigger boost factor.
	//
	// By default, all phrases or words provided in the `RecongitionContext` are
	// given an equal probability of occurring. Boost factors larger than 1 make
	// the phrase or word more probable and boost factors less than 1 make it less
	// likely. A boost factor of 2 corresponds to making the phrase or word twice
	// as likely, while a boost factor of 0.5 means half as likely.
	Boost         float32 `protobuf:"fixed32,2,opt,name=boost,proto3" json:"boost,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ContextPhrase) Reset() {
	*x = ContextPhrase{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ContextPhrase) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ContextPhrase) ProtoMessage() {}

func (x *ContextPhrase) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ContextPhrase.ProtoReflect.Descriptor instead.
func (*ContextPhrase) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{13}
}

func (x *ContextPhrase) GetText() string {
	if x != nil {
		return x.Text
	}
	return ""
}

func (x *ContextPhrase) GetBoost() float32 {
	if x != nil {
		return x.Boost
	}
	return 0
}

// Audio to be sent to the recognizer
type RecognitionAudio struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Data          []byte                 `protobuf:"bytes,1,opt,name=data,proto3" json:"data,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RecognitionAudio) Reset() {
	*x = RecognitionAudio{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RecognitionAudio) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognitionAudio) ProtoMessage() {}

func (x *RecognitionAudio) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognitionAudio.ProtoReflect.Descriptor instead.
func (*RecognitionAudio) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{14}
}

func (x *RecognitionAudio) GetData() []byte {
	if x != nil {
		return x.Data
	}
	return nil
}

// Description of a Cubic Model
type Model struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Unique identifier of the model. This identifier is used to choose the model
	// that should be used for recognition, and is specified in the
	// `RecognitionConfig` message.
	Id string `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	// Model name. This is a concise name describing the model, and may be
	// presented to the end-user, for example, to help choose which model to use
	// for their recognition task.
	Name string `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`
	// Model attributes
	Attributes    *ModelAttributes `protobuf:"bytes,3,opt,name=attributes,proto3" json:"attributes,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Model) Reset() {
	*x = Model{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Model) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Model) ProtoMessage() {}

func (x *Model) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Model.ProtoReflect.Descriptor instead.
func (*Model) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{15}
}

func (x *Model) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *Model) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *Model) GetAttributes() *ModelAttributes {
	if x != nil {
		return x.Attributes
	}
	return nil
}

// Attributes of a Cubic Model
type ModelAttributes struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Audio sample rate supported by the model
	SampleRate uint32 `protobuf:"varint,1,opt,name=sample_rate,json=sampleRate,proto3" json:"sample_rate,omitempty"`
	// Attributes specifc to supporting recognition context.
	ContextInfo   *ContextInfo `protobuf:"bytes,2,opt,name=context_info,json=contextInfo,proto3" json:"context_info,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ModelAttributes) Reset() {
	*x = ModelAttributes{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[16]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelAttributes) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelAttributes) ProtoMessage() {}

func (x *ModelAttributes) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[16]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelAttributes.ProtoReflect.Descriptor instead.
func (*ModelAttributes) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{16}
}

func (x *ModelAttributes) GetSampleRate() uint32 {
	if x != nil {
		return x.SampleRate
	}
	return 0
}

func (x *ModelAttributes) GetContextInfo() *ContextInfo {
	if x != nil {
		return x.ContextInfo
	}
	return nil
}

// Model information specifc to supporting recognition context.
type ContextInfo struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// If this is set to true, the model supports taking context information into
	// account to aid speech recognition. The information may be sent with with
	// recognition requests via RecognitionContext inside RecognitionConfig.
	SupportsContext bool `protobuf:"varint,1,opt,name=supports_context,json=supportsContext,proto3" json:"supports_context,omitempty"`
	// A list of tokens (e.g "name", "airport" etc.) that serve has placeholders
	// in the model where a client provided list of phrases or words may be used
	// to aid speech recognition and produce the exact desired recognition output.
	AllowedContextTokens []string `protobuf:"bytes,2,rep,name=allowed_context_tokens,json=allowedContextTokens,proto3" json:"allowed_context_tokens,omitempty"`
	unknownFields        protoimpl.UnknownFields
	sizeCache            protoimpl.SizeCache
}

func (x *ContextInfo) Reset() {
	*x = ContextInfo{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[17]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ContextInfo) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ContextInfo) ProtoMessage() {}

func (x *ContextInfo) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[17]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ContextInfo.ProtoReflect.Descriptor instead.
func (*ContextInfo) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{17}
}

func (x *ContextInfo) GetSupportsContext() bool {
	if x != nil {
		return x.SupportsContext
	}
	return false
}

func (x *ContextInfo) GetAllowedContextTokens() []string {
	if x != nil {
		return x.AllowedContextTokens
	}
	return nil
}

// A recognition result corresponding to a portion of audio.
type RecognitionResult struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// An n-best list of recognition hypotheses alternatives
	Alternatives []*RecognitionAlternative `protobuf:"bytes,1,rep,name=alternatives,proto3" json:"alternatives,omitempty"`
	// If this is set to true, it denotes that the result is an interim partial
	// result, and could change after more audio is processed. If unset, or set to
	// false, it denotes that this is a final result and will not change.
	//
	// Servers are not required to implement support for returning partial
	// results, and clients should generally not depend on their availability.
	IsPartial bool `protobuf:"varint,2,opt,name=is_partial,json=isPartial,proto3" json:"is_partial,omitempty"`
	// If `enable_confusion_network` was set to true in the `RecognitionConfig`,
	// and if the model supports it, a confusion network will be available in the
	// results.
	Cnet *RecognitionConfusionNetwork `protobuf:"bytes,3,opt,name=cnet,proto3" json:"cnet,omitempty"`
	// Channel of the audio file that this result was transcribed from. Channels
	// are 0-indexed, so the for mono audio data, this value will always be 0.
	AudioChannel  uint32 `protobuf:"varint,4,opt,name=audio_channel,json=audioChannel,proto3" json:"audio_channel,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RecognitionResult) Reset() {
	*x = RecognitionResult{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[18]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RecognitionResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognitionResult) ProtoMessage() {}

func (x *RecognitionResult) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[18]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognitionResult.ProtoReflect.Descriptor instead.
func (*RecognitionResult) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{18}
}

func (x *RecognitionResult) GetAlternatives() []*RecognitionAlternative {
	if x != nil {
		return x.Alternatives
	}
	return nil
}

func (x *RecognitionResult) GetIsPartial() bool {
	if x != nil {
		return x.IsPartial
	}
	return false
}

func (x *RecognitionResult) GetCnet() *RecognitionConfusionNetwork {
	if x != nil {
		return x.Cnet
	}
	return nil
}

func (x *RecognitionResult) GetAudioChannel() uint32 {
	if x != nil {
		return x.AudioChannel
	}
	return 0
}

// Developer-facing error message about a non-fatal recognition issue.
type RecognitionError struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Message       string                 `protobuf:"bytes,1,opt,name=message,proto3" json:"message,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RecognitionError) Reset() {
	*x = RecognitionError{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[19]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RecognitionError) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognitionError) ProtoMessage() {}

func (x *RecognitionError) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[19]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognitionError.ProtoReflect.Descriptor instead.
func (*RecognitionError) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{19}
}

func (x *RecognitionError) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

// A recognition hypothesis
type RecognitionAlternative struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Text representing the transcription of the words that the user spoke.
	//
	// The transcript will be formatted according to the servers formatting
	// configuration. If you want the raw transcript, please see the field
	// `transcript_raw`. If the server is configured to not use any formatting,
	// then this field will contain the raw transcript.
	//
	// As an example, if the spoken utterance was "four people", and the server
	// was configured to format numbers, this field would be set to "4 people".
	TranscriptFormatted string `protobuf:"bytes,1,opt,name=transcript_formatted,json=transcriptFormatted,proto3" json:"transcript_formatted,omitempty"`
	// Text representing the transcription of the words that the user spoke,
	// without any formatting applied. If you want the formatted transcript,
	// please see the field `transcript_formatted`.
	//
	// As an example, if the spoken utterance was `four people`, this field would
	// be set to "FOUR PEOPLE".
	TranscriptRaw string `protobuf:"bytes,2,opt,name=transcript_raw,json=transcriptRaw,proto3" json:"transcript_raw,omitempty"`
	// Time offset in milliseconds relative to the beginning of audio received by
	// the recognizer and corresponding to the start of this utterance.
	StartTimeMs uint64 `protobuf:"varint,3,opt,name=start_time_ms,json=startTimeMs,proto3" json:"start_time_ms,omitempty"`
	// Duration in milliseconds of the current utterance in the spoken audio.
	DurationMs uint64 `protobuf:"varint,4,opt,name=duration_ms,json=durationMs,proto3" json:"duration_ms,omitempty"`
	// Confidence estimate between 0 and 1. A higher number represents a higher
	// likelihood of the output being correct.
	Confidence float64 `protobuf:"fixed64,5,opt,name=confidence,proto3" json:"confidence,omitempty"`
	// Word-level details corresponding to the transcripts. This is available only
	// if `enable_word_details` was set to `true` in the `RecognitionConfig`.
	WordDetails   *WordDetails `protobuf:"bytes,6,opt,name=word_details,json=wordDetails,proto3" json:"word_details,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RecognitionAlternative) Reset() {
	*x = RecognitionAlternative{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[20]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RecognitionAlternative) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognitionAlternative) ProtoMessage() {}

func (x *RecognitionAlternative) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[20]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognitionAlternative.ProtoReflect.Descriptor instead.
func (*RecognitionAlternative) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{20}
}

func (x *RecognitionAlternative) GetTranscriptFormatted() string {
	if x != nil {
		return x.TranscriptFormatted
	}
	return ""
}

func (x *RecognitionAlternative) GetTranscriptRaw() string {
	if x != nil {
		return x.TranscriptRaw
	}
	return ""
}

func (x *RecognitionAlternative) GetStartTimeMs() uint64 {
	if x != nil {
		return x.StartTimeMs
	}
	return 0
}

func (x *RecognitionAlternative) GetDurationMs() uint64 {
	if x != nil {
		return x.DurationMs
	}
	return 0
}

func (x *RecognitionAlternative) GetConfidence() float64 {
	if x != nil {
		return x.Confidence
	}
	return 0
}

func (x *RecognitionAlternative) GetWordDetails() *WordDetails {
	if x != nil {
		return x.WordDetails
	}
	return nil
}

type WordDetails struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Word-level information corresponding to the `transcript_formatted` field.
	Formatted []*WordInfo `protobuf:"bytes,1,rep,name=formatted,proto3" json:"formatted,omitempty"`
	// Word-level information corresponding to the `transcript_raw` field.
	Raw           []*WordInfo `protobuf:"bytes,2,rep,name=raw,proto3" json:"raw,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *WordDetails) Reset() {
	*x = WordDetails{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[21]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *WordDetails) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*WordDetails) ProtoMessage() {}

func (x *WordDetails) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[21]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use WordDetails.ProtoReflect.Descriptor instead.
func (*WordDetails) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{21}
}

func (x *WordDetails) GetFormatted() []*WordInfo {
	if x != nil {
		return x.Formatted
	}
	return nil
}

func (x *WordDetails) GetRaw() []*WordInfo {
	if x != nil {
		return x.Raw
	}
	return nil
}

// Word level details for recognized words in a transcript
type WordInfo struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The actual word in the text
	Word string `protobuf:"bytes,1,opt,name=word,proto3" json:"word,omitempty"`
	// Confidence estimate between 0 and 1. A higher number represents a higher
	// likelihood that the word was correctly recognized.
	Confidence float64 `protobuf:"fixed64,2,opt,name=confidence,proto3" json:"confidence,omitempty"`
	// Time offset in milliseconds relative to the beginning of audio received by
	// the recognizer and corresponding to the start of this spoken word.
	StartTimeMs uint64 `protobuf:"varint,3,opt,name=start_time_ms,json=startTimeMs,proto3" json:"start_time_ms,omitempty"`
	// Duration in milliseconds of the current word in the spoken audio.
	DurationMs    uint64 `protobuf:"varint,4,opt,name=duration_ms,json=durationMs,proto3" json:"duration_ms,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *WordInfo) Reset() {
	*x = WordInfo{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[22]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *WordInfo) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*WordInfo) ProtoMessage() {}

func (x *WordInfo) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[22]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use WordInfo.ProtoReflect.Descriptor instead.
func (*WordInfo) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{22}
}

func (x *WordInfo) GetWord() string {
	if x != nil {
		return x.Word
	}
	return ""
}

func (x *WordInfo) GetConfidence() float64 {
	if x != nil {
		return x.Confidence
	}
	return 0
}

func (x *WordInfo) GetStartTimeMs() uint64 {
	if x != nil {
		return x.StartTimeMs
	}
	return 0
}

func (x *WordInfo) GetDurationMs() uint64 {
	if x != nil {
		return x.DurationMs
	}
	return 0
}

// Confusion network in recognition output
type RecognitionConfusionNetwork struct {
	state         protoimpl.MessageState  `protogen:"open.v1"`
	Links         []*ConfusionNetworkLink `protobuf:"bytes,1,rep,name=links,proto3" json:"links,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *RecognitionConfusionNetwork) Reset() {
	*x = RecognitionConfusionNetwork{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[23]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *RecognitionConfusionNetwork) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*RecognitionConfusionNetwork) ProtoMessage() {}

func (x *RecognitionConfusionNetwork) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[23]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use RecognitionConfusionNetwork.ProtoReflect.Descriptor instead.
func (*RecognitionConfusionNetwork) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{23}
}

func (x *RecognitionConfusionNetwork) GetLinks() []*ConfusionNetworkLink {
	if x != nil {
		return x.Links
	}
	return nil
}

// A Link inside a confusion network
type ConfusionNetworkLink struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Time offset in milliseconds relative to the beginning of audio received by
	// the recognizer and corresponding to the start of this link
	StartTimeMs uint64 `protobuf:"varint,1,opt,name=start_time_ms,json=startTimeMs,proto3" json:"start_time_ms,omitempty"`
	// Duration in milliseconds of the current link in the confusion network
	DurationMs uint64 `protobuf:"varint,2,opt,name=duration_ms,json=durationMs,proto3" json:"duration_ms,omitempty"`
	// Arcs between this link
	Arcs          []*ConfusionNetworkArc `protobuf:"bytes,3,rep,name=arcs,proto3" json:"arcs,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ConfusionNetworkLink) Reset() {
	*x = ConfusionNetworkLink{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[24]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ConfusionNetworkLink) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ConfusionNetworkLink) ProtoMessage() {}

func (x *ConfusionNetworkLink) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[24]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ConfusionNetworkLink.ProtoReflect.Descriptor instead.
func (*ConfusionNetworkLink) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{24}
}

func (x *ConfusionNetworkLink) GetStartTimeMs() uint64 {
	if x != nil {
		return x.StartTimeMs
	}
	return 0
}

func (x *ConfusionNetworkLink) GetDurationMs() uint64 {
	if x != nil {
		return x.DurationMs
	}
	return 0
}

func (x *ConfusionNetworkLink) GetArcs() []*ConfusionNetworkArc {
	if x != nil {
		return x.Arcs
	}
	return nil
}

// An Arc inside a Confusion Network Link
type ConfusionNetworkArc struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Word in the recognized transcript
	Word string `protobuf:"bytes,1,opt,name=word,proto3" json:"word,omitempty"`
	// Confidence estimate between 0 and 1. A higher number represents a higher
	// likelihood that the word was correctly recognized.
	Confidence float64 `protobuf:"fixed64,2,opt,name=confidence,proto3" json:"confidence,omitempty"`
	// Features related to this arc
	Features      *ConfusionNetworkArcFeatures `protobuf:"bytes,3,opt,name=features,proto3" json:"features,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ConfusionNetworkArc) Reset() {
	*x = ConfusionNetworkArc{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[25]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ConfusionNetworkArc) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ConfusionNetworkArc) ProtoMessage() {}

func (x *ConfusionNetworkArc) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[25]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ConfusionNetworkArc.ProtoReflect.Descriptor instead.
func (*ConfusionNetworkArc) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{25}
}

func (x *ConfusionNetworkArc) GetWord() string {
	if x != nil {
		return x.Word
	}
	return ""
}

func (x *ConfusionNetworkArc) GetConfidence() float64 {
	if x != nil {
		return x.Confidence
	}
	return 0
}

func (x *ConfusionNetworkArc) GetFeatures() *ConfusionNetworkArcFeatures {
	if x != nil {
		return x.Features
	}
	return nil
}

// Features related to confusion network arcs
type ConfusionNetworkArcFeatures struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// A map of features that are used for recalculating confidence scores of this
	// confusion network arc
	Confidence    map[string]float64 `protobuf:"bytes,1,rep,name=confidence,proto3" json:"confidence,omitempty" protobuf_key:"bytes,1,opt,name=key" protobuf_val:"fixed64,2,opt,name=value"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ConfusionNetworkArcFeatures) Reset() {
	*x = ConfusionNetworkArcFeatures{}
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[26]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ConfusionNetworkArcFeatures) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ConfusionNetworkArcFeatures) ProtoMessage() {}

func (x *ConfusionNetworkArcFeatures) ProtoReflect() protoreflect.Message {
	mi := &file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[26]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ConfusionNetworkArcFeatures.ProtoReflect.Descriptor instead.
func (*ConfusionNetworkArcFeatures) Descriptor() ([]byte, []int) {
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP(), []int{26}
}

func (x *ConfusionNetworkArcFeatures) GetConfidence() map[string]float64 {
	if x != nil {
		return x.Confidence
	}
	return nil
}

var File_cobaltspeech_cubic_v5_cubic_proto protoreflect.FileDescriptor

const file_cobaltspeech_cubic_v5_cubic_proto_rawDesc = "" +
	"\n" +
	"!cobaltspeech/cubic/v5/cubic.proto\x12\x15cobaltspeech.cubic.v5\"\x10\n" +
	"\x0eVersionRequest\"+\n" +
	"\x0fVersionResponse\x12\x18\n" +
	"\aversion\x18\x01 \x01(\tR\aversion\"\x13\n" +
	"\x11ListModelsRequest\"J\n" +
	"\x12ListModelsResponse\x124\n" +
	"\x06models\x18\x01 \x03(\v2\x1c.cobaltspeech.cubic.v5.ModelR\x06models\"\xab\x01\n" +
	"\x19StreamingRecognizeRequest\x12B\n" +
	"\x06config\x18\x01 \x01(\v2(.cobaltspeech.cubic.v5.RecognitionConfigH\x00R\x06config\x12?\n" +
	"\x05audio\x18\x02 \x01(\v2'.cobaltspeech.cubic.v5.RecognitionAudioH\x00R\x05audioB\t\n" +
	"\arequest\"\x9d\x01\n" +
	"\x1aStreamingRecognizeResponse\x12@\n" +
	"\x06result\x18\x01 \x01(\v2(.cobaltspeech.cubic.v5.RecognitionResultR\x06result\x12=\n" +
	"\x05error\x18\x02 \x01(\v2'.cobaltspeech.cubic.v5.RecognitionErrorR\x05error\"\x88\x01\n" +
	"\x15CompileContextRequest\x12\x19\n" +
	"\bmodel_id\x18\x01 \x01(\tR\amodelId\x12\x14\n" +
	"\x05token\x18\x02 \x01(\tR\x05token\x12>\n" +
	"\aphrases\x18\x03 \x03(\v2$.cobaltspeech.cubic.v5.ContextPhraseR\aphrases\"Z\n" +
	"\x16CompileContextResponse\x12@\n" +
	"\acontext\x18\x01 \x01(\v2&.cobaltspeech.cubic.v5.CompiledContextR\acontext\"\xd3\x04\n" +
	"\x11RecognitionConfig\x12\x19\n" +
	"\bmodel_id\x18\x01 \x01(\tR\amodelId\x12Q\n" +
	"\x10audio_format_raw\x18\x02 \x01(\v2%.cobaltspeech.cubic.v5.AudioFormatRAWH\x00R\x0eaudioFormatRaw\x12`\n" +
	"\x15audio_format_headered\x18\x03 \x01(\x0e2*.cobaltspeech.cubic.v5.AudioFormatHeaderedH\x00R\x13audioFormatHeadered\x126\n" +
	"\x17selected_audio_channels\x18\x04 \x03(\rR\x15selectedAudioChannels\x12/\n" +
	"\x14audio_time_offset_ms\x18\x05 \x01(\x04R\x11audioTimeOffsetMs\x12.\n" +
	"\x13enable_word_details\x18\x06 \x01(\bR\x11enableWordDetails\x128\n" +
	"\x18enable_confusion_network\x18\a \x01(\bR\x16enableConfusionNetwork\x12F\n" +
	"\bmetadata\x18\b \x01(\v2*.cobaltspeech.cubic.v5.RecognitionMetadataR\bmetadata\x12C\n" +
	"\acontext\x18\t \x01(\v2).cobaltspeech.cubic.v5.RecognitionContextR\acontextB\x0e\n" +
	"\faudio_format\"\xed\x01\n" +
	"\x0eAudioFormatRAW\x12@\n" +
	"\bencoding\x18\x01 \x01(\x0e2$.cobaltspeech.cubic.v5.AudioEncodingR\bencoding\x12\x1b\n" +
	"\tbit_depth\x18\x02 \x01(\rR\bbitDepth\x12?\n" +
	"\n" +
	"byte_order\x18\x03 \x01(\x0e2 .cobaltspeech.cubic.v5.ByteOrderR\tbyteOrder\x12\x1f\n" +
	"\vsample_rate\x18\x04 \x01(\rR\n" +
	"sampleRate\x12\x1a\n" +
	"\bchannels\x18\x05 \x01(\rR\bchannels\"[\n" +
	"\x13RecognitionMetadata\x12'\n" +
	"\x0fcustom_metadata\x18\x01 \x01(\tR\x0ecustomMetadata\x12\x1b\n" +
	"\tcustom_id\x18\x02 \x01(\tR\bcustomId\"X\n" +
	"\x12RecognitionContext\x12B\n" +
	"\bcompiled\x18\x01 \x03(\v2&.cobaltspeech.cubic.v5.CompiledContextR\bcompiled\"%\n" +
	"\x0fCompiledContext\x12\x12\n" +
	"\x04data\x18\x01 \x01(\fR\x04data\"9\n" +
	"\rContextPhrase\x12\x12\n" +
	"\x04text\x18\x01 \x01(\tR\x04text\x12\x14\n" +
	"\x05boost\x18\x02 \x01(\x02R\x05boost\"&\n" +
	"\x10RecognitionAudio\x12\x12\n" +
	"\x04data\x18\x01 \x01(\fR\x04data\"s\n" +
	"\x05Model\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12\x12\n" +
	"\x04name\x18\x02 \x01(\tR\x04name\x12F\n" +
	"\n" +
	"attributes\x18\x03 \x01(\v2&.cobaltspeech.cubic.v5.ModelAttributesR\n" +
	"attributes\"y\n" +
	"\x0fModelAttributes\x12\x1f\n" +
	"\vsample_rate\x18\x01 \x01(\rR\n" +
	"sampleRate\x12E\n" +
	"\fcontext_info\x18\x02 \x01(\v2\".cobaltspeech.cubic.v5.ContextInfoR\vcontextInfo\"n\n" +
	"\vContextInfo\x12)\n" +
	"\x10supports_context\x18\x01 \x01(\bR\x0fsupportsContext\x124\n" +
	"\x16allowed_context_tokens\x18\x02 \x03(\tR\x14allowedContextTokens\"\xf2\x01\n" +
	"\x11RecognitionResult\x12Q\n" +
	"\falternatives\x18\x01 \x03(\v2-.cobaltspeech.cubic.v5.RecognitionAlternativeR\falternatives\x12\x1d\n" +
	"\n" +
	"is_partial\x18\x02 \x01(\bR\tisPartial\x12F\n" +
	"\x04cnet\x18\x03 \x01(\v22.cobaltspeech.cubic.v5.RecognitionConfusionNetworkR\x04cnet\x12#\n" +
	"\raudio_channel\x18\x04 \x01(\rR\faudioChannel\",\n" +
	"\x10RecognitionError\x12\x18\n" +
	"\amessage\x18\x01 \x01(\tR\amessage\"\x9e\x02\n" +
	"\x16RecognitionAlternative\x121\n" +
	"\x14transcript_formatted\x18\x01 \x01(\tR\x13transcriptFormatted\x12%\n" +
	"\x0etranscript_raw\x18\x02 \x01(\tR\rtranscriptRaw\x12\"\n" +
	"\rstart_time_ms\x18\x03 \x01(\x04R\vstartTimeMs\x12\x1f\n" +
	"\vduration_ms\x18\x04 \x01(\x04R\n" +
	"durationMs\x12\x1e\n" +
	"\n" +
	"confidence\x18\x05 \x01(\x01R\n" +
	"confidence\x12E\n" +
	"\fword_details\x18\x06 \x01(\v2\".cobaltspeech.cubic.v5.WordDetailsR\vwordDetails\"\x7f\n" +
	"\vWordDetails\x12=\n" +
	"\tformatted\x18\x01 \x03(\v2\x1f.cobaltspeech.cubic.v5.WordInfoR\tformatted\x121\n" +
	"\x03raw\x18\x02 \x03(\v2\x1f.cobaltspeech.cubic.v5.WordInfoR\x03raw\"\x83\x01\n" +
	"\bWordInfo\x12\x12\n" +
	"\x04word\x18\x01 \x01(\tR\x04word\x12\x1e\n" +
	"\n" +
	"confidence\x18\x02 \x01(\x01R\n" +
	"confidence\x12\"\n" +
	"\rstart_time_ms\x18\x03 \x01(\x04R\vstartTimeMs\x12\x1f\n" +
	"\vduration_ms\x18\x04 \x01(\x04R\n" +
	"durationMs\"`\n" +
	"\x1bRecognitionConfusionNetwork\x12A\n" +
	"\x05links\x18\x01 \x03(\v2+.cobaltspeech.cubic.v5.ConfusionNetworkLinkR\x05links\"\x9b\x01\n" +
	"\x14ConfusionNetworkLink\x12\"\n" +
	"\rstart_time_ms\x18\x01 \x01(\x04R\vstartTimeMs\x12\x1f\n" +
	"\vduration_ms\x18\x02 \x01(\x04R\n" +
	"durationMs\x12>\n" +
	"\x04arcs\x18\x03 \x03(\v2*.cobaltspeech.cubic.v5.ConfusionNetworkArcR\x04arcs\"\x99\x01\n" +
	"\x13ConfusionNetworkArc\x12\x12\n" +
	"\x04word\x18\x01 \x01(\tR\x04word\x12\x1e\n" +
	"\n" +
	"confidence\x18\x02 \x01(\x01R\n" +
	"confidence\x12N\n" +
	"\bfeatures\x18\x03 \x01(\v22.cobaltspeech.cubic.v5.ConfusionNetworkArcFeaturesR\bfeatures\"\xc0\x01\n" +
	"\x1bConfusionNetworkArcFeatures\x12b\n" +
	"\n" +
	"confidence\x18\x01 \x03(\v2B.cobaltspeech.cubic.v5.ConfusionNetworkArcFeatures.ConfidenceEntryR\n" +
	"confidence\x1a=\n" +
	"\x0fConfidenceEntry\x12\x10\n" +
	"\x03key\x18\x01 \x01(\tR\x03key\x12\x14\n" +
	"\x05value\x18\x02 \x01(\x01R\x05value:\x028\x01*`\n" +
	"\tByteOrder\x12\x1a\n" +
	"\x16BYTE_ORDER_UNSPECIFIED\x10\x00\x12\x1c\n" +
	"\x18BYTE_ORDER_LITTLE_ENDIAN\x10\x01\x12\x19\n" +
	"\x15BYTE_ORDER_BIG_ENDIAN\x10\x02*\xb8\x01\n" +
	"\rAudioEncoding\x12\x1e\n" +
	"\x1aAUDIO_ENCODING_UNSPECIFIED\x10\x00\x12\x19\n" +
	"\x15AUDIO_ENCODING_SIGNED\x10\x01\x12\x1b\n" +
	"\x17AUDIO_ENCODING_UNSIGNED\x10\x02\x12\x1d\n" +
	"\x19AUDIO_ENCODING_IEEE_FLOAT\x10\x03\x12\x17\n" +
	"\x13AUDIO_ENCODING_ULAW\x10\x04\x12\x17\n" +
	"\x13AUDIO_ENCODING_ALAW\x10\x05*\xbe\x01\n" +
	"\x13AudioFormatHeadered\x12%\n" +
	"!AUDIO_FORMAT_HEADERED_UNSPECIFIED\x10\x00\x12\x1d\n" +
	"\x19AUDIO_FORMAT_HEADERED_WAV\x10\x01\x12\x1d\n" +
	"\x19AUDIO_FORMAT_HEADERED_MP3\x10\x02\x12\x1e\n" +
	"\x1aAUDIO_FORMAT_HEADERED_FLAC\x10\x03\x12\"\n" +
	"\x1eAUDIO_FORMAT_HEADERED_OGG_OPUS\x10\x042\xbf\x03\n" +
	"\fCubicService\x12Z\n" +
	"\aVersion\x12%.cobaltspeech.cubic.v5.VersionRequest\x1a&.cobaltspeech.cubic.v5.VersionResponse\"\x00\x12a\n" +
	"\n" +
	"ListModels\x12(.cobaltspeech.cubic.v5.ListModelsRequest\x1a).cobaltspeech.cubic.v5.ListModelsResponse\x12\x7f\n" +
	"\x12StreamingRecognize\x120.cobaltspeech.cubic.v5.StreamingRecognizeRequest\x1a1.cobaltspeech.cubic.v5.StreamingRecognizeResponse\"\x00(\x010\x01\x12o\n" +
	"\x0eCompileContext\x12,.cobaltspeech.cubic.v5.CompileContextRequest\x1a-.cobaltspeech.cubic.v5.CompileContextResponse\"\x00B\xe0\x01\n" +
	"\x19com.cobaltspeech.cubic.v5B\n" +
	"CubicProtoP\x01ZAgithub.com/cobaltspeech/go-genproto/cobaltspeech/cubic/v5;cubicv5\xa2\x02\x03CCX\xaa\x02\x15Cobaltspeech.Cubic.V5\xca\x02\x15Cobaltspeech\\Cubic\\V5\xe2\x02!Cobaltspeech\\Cubic\\V5\\GPBMetadata\xea\x02\x17Cobaltspeech::Cubic::V5b\x06proto3"

var (
	file_cobaltspeech_cubic_v5_cubic_proto_rawDescOnce sync.Once
	file_cobaltspeech_cubic_v5_cubic_proto_rawDescData []byte
)

func file_cobaltspeech_cubic_v5_cubic_proto_rawDescGZIP() []byte {
	file_cobaltspeech_cubic_v5_cubic_proto_rawDescOnce.Do(func() {
		file_cobaltspeech_cubic_v5_cubic_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_cobaltspeech_cubic_v5_cubic_proto_rawDesc), len(file_cobaltspeech_cubic_v5_cubic_proto_rawDesc)))
	})
	return file_cobaltspeech_cubic_v5_cubic_proto_rawDescData
}

var file_cobaltspeech_cubic_v5_cubic_proto_enumTypes = make([]protoimpl.EnumInfo, 3)
var file_cobaltspeech_cubic_v5_cubic_proto_msgTypes = make([]protoimpl.MessageInfo, 28)
var file_cobaltspeech_cubic_v5_cubic_proto_goTypes = []any{
	(ByteOrder)(0),                      // 0: cobaltspeech.cubic.v5.ByteOrder
	(AudioEncoding)(0),                  // 1: cobaltspeech.cubic.v5.AudioEncoding
	(AudioFormatHeadered)(0),            // 2: cobaltspeech.cubic.v5.AudioFormatHeadered
	(*VersionRequest)(nil),              // 3: cobaltspeech.cubic.v5.VersionRequest
	(*VersionResponse)(nil),             // 4: cobaltspeech.cubic.v5.VersionResponse
	(*ListModelsRequest)(nil),           // 5: cobaltspeech.cubic.v5.ListModelsRequest
	(*ListModelsResponse)(nil),          // 6: cobaltspeech.cubic.v5.ListModelsResponse
	(*StreamingRecognizeRequest)(nil),   // 7: cobaltspeech.cubic.v5.StreamingRecognizeRequest
	(*StreamingRecognizeResponse)(nil),  // 8: cobaltspeech.cubic.v5.StreamingRecognizeResponse
	(*CompileContextRequest)(nil),       // 9: cobaltspeech.cubic.v5.CompileContextRequest
	(*CompileContextResponse)(nil),      // 10: cobaltspeech.cubic.v5.CompileContextResponse
	(*RecognitionConfig)(nil),           // 11: cobaltspeech.cubic.v5.RecognitionConfig
	(*AudioFormatRAW)(nil),              // 12: cobaltspeech.cubic.v5.AudioFormatRAW
	(*RecognitionMetadata)(nil),         // 13: cobaltspeech.cubic.v5.RecognitionMetadata
	(*RecognitionContext)(nil),          // 14: cobaltspeech.cubic.v5.RecognitionContext
	(*CompiledContext)(nil),             // 15: cobaltspeech.cubic.v5.CompiledContext
	(*ContextPhrase)(nil),               // 16: cobaltspeech.cubic.v5.ContextPhrase
	(*RecognitionAudio)(nil),            // 17: cobaltspeech.cubic.v5.RecognitionAudio
	(*Model)(nil),                       // 18: cobaltspeech.cubic.v5.Model
	(*ModelAttributes)(nil),             // 19: cobaltspeech.cubic.v5.ModelAttributes
	(*ContextInfo)(nil),                 // 20: cobaltspeech.cubic.v5.ContextInfo
	(*RecognitionResult)(nil),           // 21: cobaltspeech.cubic.v5.RecognitionResult
	(*RecognitionError)(nil),            // 22: cobaltspeech.cubic.v5.RecognitionError
	(*RecognitionAlternative)(nil),      // 23: cobaltspeech.cubic.v5.RecognitionAlternative
	(*WordDetails)(nil),                 // 24: cobaltspeech.cubic.v5.WordDetails
	(*WordInfo)(nil),                    // 25: cobaltspeech.cubic.v5.WordInfo
	(*RecognitionConfusionNetwork)(nil), // 26: cobaltspeech.cubic.v5.RecognitionConfusionNetwork
	(*ConfusionNetworkLink)(nil),        // 27: cobaltspeech.cubic.v5.ConfusionNetworkLink
	(*ConfusionNetworkArc)(nil),         // 28: cobaltspeech.cubic.v5.ConfusionNetworkArc
	(*ConfusionNetworkArcFeatures)(nil), // 29: cobaltspeech.cubic.v5.ConfusionNetworkArcFeatures
	nil,                                 // 30: cobaltspeech.cubic.v5.ConfusionNetworkArcFeatures.ConfidenceEntry
}
var file_cobaltspeech_cubic_v5_cubic_proto_depIdxs = []int32{
	18, // 0: cobaltspeech.cubic.v5.ListModelsResponse.models:type_name -> cobaltspeech.cubic.v5.Model
	11, // 1: cobaltspeech.cubic.v5.StreamingRecognizeRequest.config:type_name -> cobaltspeech.cubic.v5.RecognitionConfig
	17, // 2: cobaltspeech.cubic.v5.StreamingRecognizeRequest.audio:type_name -> cobaltspeech.cubic.v5.RecognitionAudio
	21, // 3: cobaltspeech.cubic.v5.StreamingRecognizeResponse.result:type_name -> cobaltspeech.cubic.v5.RecognitionResult
	22, // 4: cobaltspeech.cubic.v5.StreamingRecognizeResponse.error:type_name -> cobaltspeech.cubic.v5.RecognitionError
	16, // 5: cobaltspeech.cubic.v5.CompileContextRequest.phrases:type_name -> cobaltspeech.cubic.v5.ContextPhrase
	15, // 6: cobaltspeech.cubic.v5.CompileContextResponse.context:type_name -> cobaltspeech.cubic.v5.CompiledContext
	12, // 7: cobaltspeech.cubic.v5.RecognitionConfig.audio_format_raw:type_name -> cobaltspeech.cubic.v5.AudioFormatRAW
	2,  // 8: cobaltspeech.cubic.v5.RecognitionConfig.audio_format_headered:type_name -> cobaltspeech.cubic.v5.AudioFormatHeadered
	13, // 9: cobaltspeech.cubic.v5.RecognitionConfig.metadata:type_name -> cobaltspeech.cubic.v5.RecognitionMetadata
	14, // 10: cobaltspeech.cubic.v5.RecognitionConfig.context:type_name -> cobaltspeech.cubic.v5.RecognitionContext
	1,  // 11: cobaltspeech.cubic.v5.AudioFormatRAW.encoding:type_name -> cobaltspeech.cubic.v5.AudioEncoding
	0,  // 12: cobaltspeech.cubic.v5.AudioFormatRAW.byte_order:type_name -> cobaltspeech.cubic.v5.ByteOrder
	15, // 13: cobaltspeech.cubic.v5.RecognitionContext.compiled:type_name -> cobaltspeech.cubic.v5.CompiledContext
	19, // 14: cobaltspeech.cubic.v5.Model.attributes:type_name -> cobaltspeech.cubic.v5.ModelAttributes
	20, // 15: cobaltspeech.cubic.v5.ModelAttributes.context_info:type_name -> cobaltspeech.cubic.v5.ContextInfo
	23, // 16: cobaltspeech.cubic.v5.RecognitionResult.alternatives:type_name -> cobaltspeech.cubic.v5.RecognitionAlternative
	26, // 17: cobaltspeech.cubic.v5.RecognitionResult.cnet:type_name -> cobaltspeech.cubic.v5.RecognitionConfusionNetwork
	24, // 18: cobaltspeech.cubic.v5.RecognitionAlternative.word_details:type_name -> cobaltspeech.cubic.v5.WordDetails
	25, // 19: cobaltspeech.cubic.v5.WordDetails.formatted:type_name -> cobaltspeech.cubic.v5.WordInfo
	25, // 20: cobaltspeech.cubic.v5.WordDetails.raw:type_name -> cobaltspeech.cubic.v5.WordInfo
	27, // 21: cobaltspeech.cubic.v5.RecognitionConfusionNetwork.links:type_name -> cobaltspeech.cubic.v5.ConfusionNetworkLink
	28, // 22: cobaltspeech.cubic.v5.ConfusionNetworkLink.arcs:type_name -> cobaltspeech.cubic.v5.ConfusionNetworkArc
	29, // 23: cobaltspeech.cubic.v5.ConfusionNetworkArc.features:type_name -> cobaltspeech.cubic.v5.ConfusionNetworkArcFeatures
	30, // 24: cobaltspeech.cubic.v5.ConfusionNetworkArcFeatures.confidence:type_name -> cobaltspeech.cubic.v5.ConfusionNetworkArcFeatures.ConfidenceEntry
	3,  // 25: cobaltspeech.cubic.v5.CubicService.Version:input_type -> cobaltspeech.cubic.v5.VersionRequest
	5,  // 26: cobaltspeech.cubic.v5.CubicService.ListModels:input_type -> cobaltspeech.cubic.v5.ListModelsRequest
	7,  // 27: cobaltspeech.cubic.v5.CubicService.StreamingRecognize:input_type -> cobaltspeech.cubic.v5.StreamingRecognizeRequest
	9,  // 28: cobaltspeech.cubic.v5.CubicService.CompileContext:input_type -> cobaltspeech.cubic.v5.CompileContextRequest
	4,  // 29: cobaltspeech.cubic.v5.CubicService.Version:output_type -> cobaltspeech.cubic.v5.VersionResponse
	6,  // 30: cobaltspeech.cubic.v5.CubicService.ListModels:output_type -> cobaltspeech.cubic.v5.ListModelsResponse
	8,  // 31: cobaltspeech.cubic.v5.CubicService.StreamingRecognize:output_type -> cobaltspeech.cubic.v5.StreamingRecognizeResponse
	10, // 32: cobaltspeech.cubic.v5.CubicService.CompileContext:output_type -> cobaltspeech.cubic.v5.CompileContextResponse
	29, // [29:33] is the sub-list for method output_type
	25, // [25:29] is the sub-list for method input_type
	25, // [25:25] is the sub-list for extension type_name
	25, // [25:25] is the sub-list for extension extendee
	0,  // [0:25] is the sub-list for field type_name
}

func init() { file_cobaltspeech_cubic_v5_cubic_proto_init() }
func file_cobaltspeech_cubic_v5_cubic_proto_init() {
	if File_cobaltspeech_cubic_v5_cubic_proto != nil {
		return
	}
	file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[4].OneofWrappers = []any{
		(*StreamingRecognizeRequest_Config)(nil),
		(*StreamingRecognizeRequest_Audio)(nil),
	}
	file_cobaltspeech_cubic_v5_cubic_proto_msgTypes[8].OneofWrappers = []any{
		(*RecognitionConfig_AudioFormatRaw)(nil),
		(*RecognitionConfig_AudioFormatHeadered)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_cobaltspeech_cubic_v5_cubic_proto_rawDesc), len(file_cobaltspeech_cubic_v5_cubic_proto_rawDesc)),
			NumEnums:      3,
			NumMessages:   28,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_cobaltspeech_cubic_v5_cubic_proto_goTypes,
		DependencyIndexes: file_cobaltspeech_cubic_v5_cubic_proto_depIdxs,
		EnumInfos:         file_cobaltspeech_cubic_v5_cubic_proto_enumTypes,
		MessageInfos:      file_cobaltspeech_cubic_v5_cubic_proto_msgTypes,
	}.Build()
	File_cobaltspeech_cubic_v5_cubic_proto = out.File
	file_cobaltspeech_cubic_v5_cubic_proto_goTypes = nil
	file_cobaltspeech_cubic_v5_cubic_proto_depIdxs = nil
}
